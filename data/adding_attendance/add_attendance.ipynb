{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Attendance Points Script\n",
    "**Ben Paulson -- 9/12/2023**<br>\n",
    "\n",
    "Given a specific attendance-points form (same format), can parse and add the points to each student that filled out the form. Warnings will be provided for students that are not already included in the form or if there was a typo.<br>\n",
    "\n",
    "A format to follow is the following W2 attendance form from 2023: https://forms.office.com/Pages/DesignPageV2.aspx?prevorigin=Marketing&origin=NeoPortalPage&subpage=design&id=rM5GQNP9yUasgLfEpJurcGAyFplwhXJCtqB2wsxmGVlUNERLT0g1N0IzOU9aVk1INjE5S0w5VjBRQS4u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl # Able to parse excel files using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Parsing the Provided CSV Files\n",
    "Files in `to_parse` folder will be analyzed and points will be added. Once the sheet is analyzed, will be deleted to save AWS storage costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_df = {} # {file_name: df}\n",
    "\n",
    "# Read through all files in the `to_parse` folder\n",
    "directory_name = './to_parse'\n",
    "for file in os.listdir(directory_name):\n",
    "    if file.endswith('.xlsx'):\n",
    "        file_name = directory_name + '/' + file\n",
    "        attendance_df[file_name] = pd.read_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_data = pd.read_csv('../../data/User_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notna(website_data.loc[100, 'Awards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulsonb\\AppData\\Local\\Temp\\ipykernel_8848\\2155176163.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['email'] = df['Last Name'] + df['First Name'].str[0] + '@msoe.edu'\n",
      "C:\\Users\\paulsonb\\AppData\\Local\\Temp\\ipykernel_8848\\2155176163.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['email'] = df['email'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Create the member_list.csv\n",
    "# df = website_data\n",
    "# df['First Name'] = df['User'].str.split(' ').str[0]\n",
    "# df['Last Name'] = df['User'].str.split(' ').str[1]\n",
    "# df = df[['First Name', 'Last Name']]\n",
    "\n",
    "# # Create a new column called 'email'\n",
    "# # Email is last_name + first letter of first name + @msoe.edu (all lowercase)\n",
    "# df['email'] = df['Last Name'] + df['First Name'].str[0] + '@msoe.edu'\n",
    "# df['email'] = df['email'].str.lower()\n",
    "\n",
    "# df.to_csv('member_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Ben Weber is not in the website_data df\n",
      "WARNING: Sam Sterritt is not in the website_data df\n",
      "WARNING: Evan Roegner is not in the website_data df\n",
      "WARNING: Wilfried Tapsoba is not in the website_data df\n",
      "WARNING: Bret Storoe is not in the website_data df\n",
      "WARNING: Graham Gilsdorf is not in the website_data df\n"
     ]
    }
   ],
   "source": [
    "for file_name,df in zip(attendance_df.keys(), attendance_df.values()):\n",
    "    attendance_names = df['First and Last Name'].tolist()\n",
    "    \n",
    "    # Print a warning for each of the attendance_names which are not in the 'User' column of the website_data df\n",
    "    ADD_MISSING_USERS = True\n",
    "    ADD_BADGE = None\n",
    "    for name in attendance_names:\n",
    "        name = name.strip()\n",
    "        name = name.title()\n",
    "\n",
    "        # Create the list website_data['User'].tolist() and apply .strip() and .title() to each element\n",
    "        name_list = website_data['User'].apply(lambda x: x.strip().title()).tolist()\n",
    "        if name not in name_list:\n",
    "            print(f'WARNING: {name} is not in the website_data df')\n",
    "            \n",
    "            if ADD_MISSING_USERS:\n",
    "                website_data = pd.concat([website_data, pd.DataFrame({'User': [name], 'Description': ['test description'], 'Awards':[''], 'All-Time Points': [0], 'Current Points': [0]})], ignore_index=True)\n",
    "\n",
    "        # If name in list and ADD_BADGE isn't None, add the badge to their 'Awards' column\n",
    "        if ADD_BADGE:\n",
    "            index = name_list.index(name)\n",
    "            # If they already have a badge, add the new badge w/ '|' at beginning\n",
    "            if pd.notna(website_data.loc[index, 'Awards']):\n",
    "                website_data.loc[index, 'Awards'] += f'|{ADD_BADGE}'\n",
    "            # If they don't have a badge, add the new badge w/o '|' at beginning\n",
    "            else:\n",
    "                website_data.loc[index, 'Awards'] = ADD_BADGE\n",
    "            \n",
    "\n",
    "    # Filter out all records in the website_data df where the 'User' column isn't in the attendance_names list\n",
    "    filtered_website_data = website_data[website_data['User'].isin(attendance_names)]\n",
    "\n",
    "    # For all the records that are in filtred_website_data, add a 1 to the 'All-Time Points' and 'Current Points' columns in the website_data df\n",
    "    for index, row in filtered_website_data.iterrows():\n",
    "        website_data.loc[index, 'All-Time Points'] += 1\n",
    "        website_data.loc[index, 'Current Points'] += 1\n",
    "    \n",
    "    # Save the updated website_data df to a csv file\n",
    "    website_data.to_csv('../../data/User_Data.csv', index=False)\n",
    "\n",
    "    # Delete the file once finished parsing\n",
    "    os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If anyone in website_data has 0 All-Time Points and 0 Current Points (at the same time), make sure they are at least given 1 point\n",
    "website_data.loc[(website_data['All-Time Points'] == 0) & (website_data['Current Points'] == 0), 'All-Time Points'] = 1\n",
    "website_data.to_csv('../../data/User_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
