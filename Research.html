<body>
    <head>
        <title>MAIC - Research</title>
        <link rel="icon" type="image/png" href="./img/misc/Sticker.png">
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="./js-css/style.css">
        <link rel="stylesheet" href="./js-css/Research.css">
    </head>
    <div id="toolbar" style="text-align: center;">
        <h3><a><img src="img/misc/Sticker.png" height="25" style="float: left; padding-right: 10px; padding-top: 5px; padding-bottom: 5px;"></a></h3>
        <a href="index.html"><p>Home</p></a>
        <a href="Learning_Resources.html"><p>Learning Resources</p></a>
        <a href="Research.html" style="background-color: rgb(55, 34, 107); font-weight: bold; padding-top: 5px; padding-bottom: 5px; border-radius: 10px;"><p>Research</p></a>
        <a href="Workshops.html"><p>Workshops</p></a>
        <a href="Merch.html"><p>Merch</p></a>
        <a href="Contact.html"><p>Contact</p></a>
        <a href="About.html"><p>About</p></a>
    </div>
    <body style="padding-right: 20px; padding-left: 20px;">
        <div class="card">
            <h1>MAIC Research</h1>
            <div class="break"></div>
            <h3>
                        Our research groups are the <span style = 'font-weight: bold; color: yellow;'>best opportunity</span> we offer students for getting <span style = 'font-weight: bold; color: rgb(var(--hl-2));'>hands-on experience with developing AI technologies</span>.<br>
                        </h3>
            <div>

                                All levels of understanding are welcome; in fact, <span style = 'font-weight: bold;'>we encourage Freshman to join</span> so they can start building their knowledge about AI even before their MSOE education. 
                                To accomplish this, these groups are facilitated in a mentor/mentee style, driven by other students or industry partners on projects which provide both a motivated purpose and pathway for a final publication.
                                After hosting over 15 research groups these past two years, with over half published and presented at conferences, we hope you will join us in developing the technology of tomorrow!<br><br>
                                <span style = 'font-weight: bold;'>Below is a list of completed and ongoing research MAIC members have led.</span> <br><br>
            
            </div>
            <h1>Our Research Groups</h1>
            <div style="color: gray;">

                                To sign up, please either attend the introductory meetings at the beginning of the Fall Semester for a sign-up form or reach out to an eboard member before the end of October.
            
            </div>
        </div>
    </body>
    <!-- HTML Generated By Script -->
    <!DOCTYPE html>
    <html>
        <body>
            <div id="Research-BART" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>Bot Automated Response Technology​ (BART): MSOE Chat Bot ​</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/chat_bot.jpg" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Mazen Hamid, Nikhil Gajghate, Bark Gebka, Matej Koncos, Justin Benning</p>
                    <p><strong>Problem:</strong> Researching through the Academic Catalog is tedious when wanting to find information about the university​</p>
                    <p><strong>Approach:​</strong> Using a transformer to “learn” the catalog and be able to answer questions about the university and courses​</p>
                    <p><strong>Progress:​</strong> Currently working on a proof-of-concept LSTM model with the SQUAD dataset​
                    ​</p>
                </div>
            </div>
            <div id="Research-DNA-GAT" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>DNA GAT</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/DNA-GAT.PNG" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Alex Drobek, Arman Hossain, Collin Schmocker</p>
                    <p><strong>Problem:​</strong> Genomic Inversion Detection​</p>
                    <p><strong>Approach:​</strong> Graph Attention Networks (GATs)​</p>
                    <p><strong>Progress:​</strong> Formatting Data for Graph Input​</p>
                </div>
            </div>
            <div id="Research-Emotion-FC" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>Emotion FC: Facial Emotion Recognition from photographs​</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/Sentiment-Analysis.png" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members</strong> Hugo Garrido-Lestache, Alexander Chapovalov, Samuel Abel, Alex Ruchti, Ryan Canalia</p>
                    <p><strong>Approach:</strong> Image classification via convolutional neural networks​. (Given a photograph of a face, what is their <em>emotion</em>?​)</p>
                    <p><strong>Progress:​</strong> Acquired dataset​, Made repository​, Built basic model​</p>
                    <p><strong>Next Steps:​</strong> Tie data to model​, Train model​</p>
                </div>
            </div>
            <div id="Research-Moon-Men" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>Moon Men: MoonBoard Route Classification and Generation​</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/Moon-Men.PNG"" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Aiden Miller, Joshua Grant, Carter ulschmid, Aydin Ruppe, Michael Kirkton, Benjamin Weber</p>
                    <p><strong>Problem:​</strong> Classifying and generating MoonBoard routes​</p>
                    <p><strong>Approach:​</strong> Putting holds into a series and using Transformer​</p>
                    <p><strong>Progress​:</strong> Working classification model ​</p>
                </div>
            </div>
            <div id="Research-Stonks" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>sToNKs  : Stock prediction​</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/Stonks_Team.png" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Ben Fouch, Luka Harwood, Kevin Paganini, John Webmeier, Ryan Peter, Hunter Fritchen, Jackson Rolando</p>
                    <p><strong>Problem:​</strong> Stock movement prediction​</p>
                    <p><strong>Approach​:</strong> Collecting data from lots of different sources to get a more whole picture of what is influencing the price of the stock. ​</p>
                    <p><strong>Progress​:</strong> Data collected from reddit, twitter, news sources, and financial data (ticker prices, quarterly data, fundamentals) ​</p>
                </div>
            </div>
            <div id="Research-Traffic-Jam" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>Traffic Jam</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/Traffic_Jam.png" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members</strong> John Olson, Nathan Johnson, Zachary Stoffel, Noah Nieberle, Thomas Benzshawel, Michael Conner, Alex Moran, Bart Gebka</p>
                    <p><strong>Problem:​</strong> Traffic control solutions are too slow or out-dated</p>
                </div>
            </div>
            <div id="Research-Transformer-Troubadours" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>The Transformer Troubadors</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/Transformer-Troubadours.PNG" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Luke Harwood, Code Steinmetz, Adam Buker, Andy Dao, Jiri Liska, Lucas Gral</p>
                    <p><strong>Problem​:</strong> Music be hard​</p>
                    <p><strong>Approach:​</strong> Sequence to Sequence Transformer​, Take in part of a midi song, fill in the rest​</p>
                    <p><strong>Progress​:</strong> We have data​, Setting up data processing pipeline​, Setting up model</p>
                </div>
            </div>
            <div id="Research-Video-Smootherizer" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>Video Smootherizer</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/Video-Smootherizer.png" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Tillie Pasternak, Mitchell Johnstone, Autumn Beyer, Tyler Schreiber, Ryan Kruk</p>
                    <p><strong>Problem​:</strong> Videos don't be smooth​</p>
                    <p><strong>Approach​:</strong> Transformer​</p>
                    <p><strong>Progress​:</strong> Currently training on ROSIE!</p>
                </div>
            </div>
            <div id="Research-Video-to-Audio-Generator" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>Team 7: Video to Audio Generator​</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="../maic/img/thumbnails/AI_Electronic_Beats.png" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Samir Mahmud, Kong Xiong, Konrad Rozpadek, Adam Haile, Xander Neuwirth</p>
                    <p><strong>Problem:​</strong> Take video frames, predict the audio​</p>
                    <p><strong>Approach​:</strong> Deep learning: Frame encoder and Audio Decoder​</p>
                    <p><strong>Progress​:</strong> Have a script written that extracts frames from videos with manually applied labels​, Jupyter Notebook to train a CNN meant to categorize the frames of video and predict what category of video is shown​</p>
                    <p>​</p>
                </div>
            </div>
            <div id="Research-XprospeCT" style="background-image: url(./img/misc/NN_background_pattern_2.png); background-size: cover; border-radius: 30px; border-style: solid; border-width: 3px; border-color: gray; padding-bottom: 35px; padding-right: 5%; padding-left: 5%; overflow: auto; margin-bottom: 20px;">
                <div>
                    <h1>XprospeCT​</h1>
                </div>
                <div class="break"></div>
                <div style="float: left; padding-right: 20px; padding-bottom: 20px;">
                    <img src="./img/thumbnails/v3_ROSIE_BP_Model.gif" height="170">
                </div>
                <div style="max-width:80%;">
                    <p><strong>Members:</strong> Ben Paulson, Sydney Balboni, John Cisler, Theodore Colwell, Natalia Bukowski, Joshua Goldshteyn, Julia Kalish, Andrew Crisler</p>
                    <p><strong>Problem:​</strong> Getting CT scans is expensive and exposes patients to significant levels of radiation​. This is especially problematic is patients have chronic conditions that require scans often​; however, Chest X-rays are one of the lowest radiation imaging forms available​. What if there was a way to create a more helpful view from just two chest X-rays?​</p>
                    <p><strong>Approach:​</strong> We are planning on using a complex CNN with residual connections to create a 2D view to 3D view converter​. The 2D views will be created by using a CycleGAN style transfer to convert from Averaged CT scan views to X-ray style, and the main model will use 2D to 3D upscaling convolution layers​.</p>
                    <p><strong>Progress​</strong> Currently finalizing publication and future work development around the use of a transformer model.
                    ​</p>
                </div>
            </div>
        </body>
    </html>
</body>