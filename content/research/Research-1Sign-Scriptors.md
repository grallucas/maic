summary: The Sign Scripters implemented a state of the art model for interpreting videos of sign language into text. Their approach is based on a variant of transformers called squeeze formers which utilize CNN's to create embeddings from picture data. The input data is gathered from google machine vision to create landmarks of coordinates of the different bones in the hands and face. They hope to adapt this work into an application to help with sign language education.
type: anchor - Research
date: 2023-2024
title: Sign Scripters
image: ./img/thumbnails/Sign_Scriptors.png
difficulty: easy
authors: Michael Conner
