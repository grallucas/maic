summary: This group is working on a project to generate realistic audio from silent videos using a novel deep learning approach. They use a Seq2Seq model with a VQ-VAE encoder and a SoundStream decoder to capture the videoâ€™s visual context and produce corresponding sound waves. They test their model on a subset of Youtube8M videos and show its potential for various applications.
type: anchor - Research
date: 2023-2024
title: Silent Sound Synthesizers
image: ./img/thumbnails/Silent_Sound_Synthesizers.png"
difficulty: easy
authors: Adam Haile
files: Synthesizing Audio from Silent Video using Sequence to Sequence Modeling
